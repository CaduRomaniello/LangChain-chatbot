{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import LLMChain\n",
    "import langchain_core\n",
    "\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    ")\n",
    "from langchain_core.messages import SystemMessage, AIMessage, HumanMessage\n",
    "\n",
    "from langchain.pydantic_v1 import BaseModel, Field, validator\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./docs\\\\Tratamento completo - PDF - final.pdf', './docs\\\\AnnaPegova\\\\Descritivo Produtos - Home Care - WhatsApp - Anna Pegova.pdf', './docs\\\\AnnaPegova\\\\Manual da Marca Anna Pegova - 2021.pdf', './docs\\\\Preco\\\\Linha Profissional ComposiÃ§Ã£o - Fev 24.pdf', './docs\\\\Preco\\\\Listas de PreÃ§o Atualizadas - OUTUBRO 2023.pdf', './docs\\\\Produtos\\\\Manual de Produtos 2023.pdf', './docs\\\\Produtos\\\\PROTOCOLOS SOS EPIGEN_Est.pdf', './docs\\\\Produtos\\\\TOP 20 PRODUTOS - versÃ£o pdf.pdf']\n"
     ]
    }
   ],
   "source": [
    "arquivos_pdf = []\n",
    "for root, dirs, files in os.walk(\"./docs\"):\n",
    "    for file in files:\n",
    "        if file.endswith('.pdf'):\n",
    "            arquivos_pdf.append(os.path.join(root, file))\n",
    "print(arquivos_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserData(BaseModel):\n",
    "    name: str = Field(description=\"name of the user\")\n",
    "    email: str = Field(description=\"email of the user\")\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=UserData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=\"VocÃª Ã© um assistente que interage com o usuÃ¡rio de forma amigÃ¡vel e educada e traduz o texto para inglÃªs somente quando o usuÃ¡rio pedir para vocÃª fazer isso. VocÃª pode responder perguntas, contar piadas, contar histÃ³rias, entre outras coisas. VocÃª Ã© um assistente de linguagem que ajuda o usuÃ¡rio a se comunicar melhor. Sempre que o usuÃ¡rio perguntar explicitamente o nome dele, o telefone dele ou o email dele e vocÃª souber a resposta informe da maneira mais simplis possÃ­vel essas informaÃ§Ãµes sem palavras ou frases adicionais, caso nÃ£o saiba informe que nÃ£o possui tais informaÃ§Ãµes e peÃ§a para que ele te informe.\"\n",
    "        ),  # The persistent system prompt\n",
    "        MessagesPlaceholder(\n",
    "            variable_name=\"chat_history\"\n",
    "        ),  # Where the memory will be stored.\n",
    "        HumanMessagePromptTemplate.from_template(\n",
    "            \"{input}\"\n",
    "        ),  # Where the human input will injected\n",
    "    ]\n",
    ")\n",
    "prompt.partial_variables = {\"format_instructions\":parser.get_format_instructions()}\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_llm_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    "    memory=memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: VocÃª Ã© um assistente que interage com o usuÃ¡rio de forma amigÃ¡vel e educada e traduz o texto para inglÃªs somente quando o usuÃ¡rio pedir para vocÃª fazer isso. VocÃª pode responder perguntas, contar piadas, contar histÃ³rias, entre outras coisas. VocÃª Ã© um assistente de linguagem que ajuda o usuÃ¡rio a se comunicar melhor. Sempre que o usuÃ¡rio perguntar explicitamente o nome dele, o telefone dele ou o email dele e vocÃª souber a resposta informe da maneira mais simplis possÃ­vel essas informaÃ§Ãµes sem palavras ou frases adicionais, caso nÃ£o saiba informe que nÃ£o possui tais informaÃ§Ãµes e peÃ§a para que ele te informe.\n",
      "Human: OlÃ¡, meu nome Ã© Cadu e meu email Ã© cccc@hotmail.com, tudo bem com vocÃª?\n",
      "AI: OlÃ¡ Cadu! ðŸ˜Š\n",
      "VocÃª poderia me informar seu nÃºmero de telefone, por favor?\n",
      "Human: OlÃ¡, meu nome Ã© Cadu e meu email Ã© cccc@hotmail.com, tudo bem com vocÃª?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "output = chat_llm_chain.invoke(input=\"OlÃ¡, meu nome Ã© Cadu e meu email Ã© cccc@hotmail.com, tudo bem com vocÃª?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: VocÃª Ã© um assistente que interage com o usuÃ¡rio de forma amigÃ¡vel e educada e traduz o texto para inglÃªs somente quando o usuÃ¡rio pedir para vocÃª fazer isso. VocÃª pode responder perguntas, contar piadas, contar histÃ³rias, entre outras coisas. VocÃª Ã© um assistente de linguagem que ajuda o usuÃ¡rio a se comunicar melhor. Sempre que o usuÃ¡rio perguntar explicitamente o nome dele, o telefone dele ou o email dele e vocÃª souber a resposta informe da maneira mais simplis possÃ­vel essas informaÃ§Ãµes sem palavras ou frases adicionais, caso nÃ£o saiba informe que nÃ£o possui tais informaÃ§Ãµes e peÃ§a para que ele te informe.\n",
      "Human: OlÃ¡, meu nome Ã© Cadu e meu email Ã© cccc@hotmail.com, tudo bem com vocÃª?\n",
      "AI: OlÃ¡ Cadu! ðŸ˜Š\n",
      "VocÃª poderia me informar seu nÃºmero de telefone, por favor?\n",
      "Human: OlÃ¡, meu nome Ã© Cadu e meu email Ã© cccc@hotmail.com, tudo bem com vocÃª?\n",
      "AI: OlÃ¡ Cadu! ðŸ˜Š\n",
      "VocÃª poderia me informar seu nÃºmero de telefone, por favor?\n",
      "Human: Qual meu nome e meu email?\n",
      "AI: Seu nome Ã© Cadu e seu email Ã© cccc@hotmail.com. ðŸ˜Š\n",
      "Posso te ajudar com mais alguma coisa?\n",
      "Human: Qual meu nome e meu email?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for Generation\ntext\n  str type expected (type=type_error.str)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m output \u001b[38;5;241m=\u001b[39m chat_llm_chain\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQual meu nome e meu email?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_core\\output_parsers\\base.py:178\u001b[0m, in \u001b[0;36mBaseOutputParser.invoke\u001b[1;34m(self, input, config)\u001b[0m\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[0;32m    170\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_result(\n\u001b[0;32m    171\u001b[0m             [ChatGeneration(message\u001b[38;5;241m=\u001b[39minner_input)]\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    175\u001b[0m         run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    176\u001b[0m     )\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_core\\runnables\\base.py:1405\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[1;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[0;32m   1401\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[0;32m   1402\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(var_child_runnable_config\u001b[38;5;241m.\u001b[39mset, child_config)\n\u001b[0;32m   1403\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[0;32m   1404\u001b[0m         Output,\n\u001b[1;32m-> 1405\u001b[0m         \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1406\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1407\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1408\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1409\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1410\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1411\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1412\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   1413\u001b[0m     )\n\u001b[0;32m   1414\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1415\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_core\\runnables\\config.py:326\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[1;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[0;32m    325\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[1;32m--> 326\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_core\\output_parsers\\base.py:179\u001b[0m, in \u001b[0;36mBaseOutputParser.invoke.<locals>.<lambda>\u001b[1;34m(inner_input)\u001b[0m\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[0;32m    170\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_result(\n\u001b[0;32m    171\u001b[0m             [ChatGeneration(message\u001b[38;5;241m=\u001b[39minner_input)]\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    175\u001b[0m         run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    176\u001b[0m     )\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[1;32m--> 179\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_result([\u001b[43mGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m]),\n\u001b[0;32m    180\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m    181\u001b[0m         config,\n\u001b[0;32m    182\u001b[0m         run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    183\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_core\\load\\serializable.py:120\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 120\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lc_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pydantic\\v1\\main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[0;32m    339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[1;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m'\u001b[39m, values)\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for Generation\ntext\n  str type expected (type=type_error.str)"
     ]
    }
   ],
   "source": [
    "output = chat_llm_chain.invoke(input=\"Qual meu nome e meu email?\")\n",
    "parser.invoke(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: VocÃª Ã© um assistente que interage com o usuÃ¡rio de forma amigÃ¡vel e educada e traduz o texto para inglÃªs somente quando o usuÃ¡rio pedir para vocÃª fazer isso. VocÃª pode responder perguntas, contar piadas, contar histÃ³rias, entre outras coisas. VocÃª Ã© um assistente de linguagem que ajuda o usuÃ¡rio a se comunicar melhor. Sempre que o usuÃ¡rio perguntar o nome dele, o telefone dele ou o email dele e vocÃª souber a resposta informe da maneira mais simplis possÃ­vel essas informaÃ§Ãµes sem palavras ou frases adicionais, caso nÃ£o saiba informe que nÃ£o possui tais informaÃ§Ãµes e peÃ§a para que ele te informe.\n",
      "Human: OlÃ¡, sou o Cadu, tudo bem?\n",
      "AI: OlÃ¡, Cadu! Tudo bem sim, e contigo? Como posso te ajudar hoje?\n",
      "Human: Qual o meu nome?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Qual o meu nome?',\n",
       " 'chat_history': [HumanMessage(content='OlÃ¡, sou o Cadu, tudo bem?'),\n",
       "  AIMessage(content='OlÃ¡, Cadu! Tudo bem sim, e contigo? Como posso te ajudar hoje?'),\n",
       "  HumanMessage(content='Qual o meu nome?'),\n",
       "  AIMessage(content='Cadu')],\n",
       " 'text': 'Cadu'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_llm_chain.invoke(input=\"Qual o meu nome?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: VocÃª Ã© um assistente que interage com o usuÃ¡rio de forma amigÃ¡vel e educada e traduz o texto para inglÃªs somente quando o usuÃ¡rio pedir para vocÃª fazer isso. VocÃª pode responder perguntas, contar piadas, contar histÃ³rias, entre outras coisas. VocÃª Ã© um assistente de linguagem que ajuda o usuÃ¡rio a se comunicar melhor.\n",
      "Human: OlÃ¡, sou o Cadu, tudo bem?\n",
      "AI: OlÃ¡ Cadu! Estou bem, obrigado por perguntar. Como posso te ajudar hoje?\n",
      "Human: Qual o meu nome?\n",
      "AI: Seu nome Ã© Cadu. Posso te ajudar com mais alguma coisa?\n",
      "Human: Traduza a seguinte frase: Hoje o dia amanheceu nublado e provavelemente choverÃ¡.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Traduza a seguinte frase: Hoje o dia amanheceu nublado e provavelemente choverÃ¡.',\n",
       " 'chat_history': [HumanMessage(content='OlÃ¡, sou o Cadu, tudo bem?'),\n",
       "  AIMessage(content='OlÃ¡ Cadu! Estou bem, obrigado por perguntar. Como posso te ajudar hoje?'),\n",
       "  HumanMessage(content='Qual o meu nome?'),\n",
       "  AIMessage(content='Seu nome Ã© Cadu. Posso te ajudar com mais alguma coisa?'),\n",
       "  HumanMessage(content='Traduza a seguinte frase: Hoje o dia amanheceu nublado e provavelemente choverÃ¡.'),\n",
       "  AIMessage(content='Claro! Aqui estÃ¡ a traduÃ§Ã£o da frase para o inglÃªs: \"Today the day dawned cloudy and it will probably rain.\" \\n\\nPrecisa de mais alguma traduÃ§Ã£o ou de outra ajuda?')],\n",
       " 'text': 'Claro! Aqui estÃ¡ a traduÃ§Ã£o da frase para o inglÃªs: \"Today the day dawned cloudy and it will probably rain.\" \\n\\nPrecisa de mais alguma traduÃ§Ã£o ou de outra ajuda?'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_llm_chain.invoke(input=\"Traduza a seguinte frase: Hoje o dia amanheceu nublado e provavelemente choverÃ¡.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='OlÃ¡, sou o Cadu, tudo bem?'),\n",
       " AIMessage(content='OlÃ¡ Cadu! Estou bem, obrigado por perguntar. Como posso te ajudar hoje?'),\n",
       " HumanMessage(content='Qual o meu nome?'),\n",
       " AIMessage(content='Seu nome Ã© Cadu. Posso te ajudar com mais alguma coisa?'),\n",
       " HumanMessage(content='Traduza a seguinte frase: Hoje o dia amanheceu nublado e provavelemente choverÃ¡.'),\n",
       " AIMessage(content='Claro! Aqui estÃ¡ a traduÃ§Ã£o da frase para o inglÃªs: \"Today the day dawned cloudy and it will probably rain.\" \\n\\nPrecisa de mais alguma traduÃ§Ã£o ou de outra ajuda?')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_llm_chain.memory.chat_memory.messages"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
